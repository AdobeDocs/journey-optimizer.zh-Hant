---
product: experience platform
solution: Experience Platform
title: 個性化優化模型
description: 深入了解個人化最佳化模型
feature: Ranking Formulas
role: User
level: Intermediate
exl-id: c73b3092-e96d-4957-88e6-500e99542782
source-git-commit: c530905eacbdf6161f6449d7a0b39c8afaf3a321
workflow-type: tm+mt
source-wordcount: '817'
ht-degree: 0%

---

# 個性化優化模型 {#personalized-optimization-model}

>[!CAUTION]
>
>個人化最佳化模型目前僅供選取使用者提早存取。

## 概述 {#overview}

透過運用監控機器學習和深入學習中的最新技術，自動個人化可讓企業使用者（行銷人員）定義業務目標，並運用其客戶資料來訓練業務導向模型以提供個人化優惠方案並最大化KPI。

## 主要模型假設及限制 {#key}

為了充分發揮使用自動個人化的優點，需注意一些重要假設和限制。

* **選件的不同程度，讓使用者在考慮的選件中有不同的偏好設定**. 如果選件太相似，則產生的模型影響會較小，因為回應似乎是隨機的。
例如，如果某家銀行有兩個信用卡選件，唯一的區別是顏色，那麼建議使用哪張卡片可能並不重要，但如果每張卡片的條款不同，這就為某些客戶選擇一張提供了理由，並提供了足夠差異來構建更具影響力的模型。
* **用戶流量組合穩定**. 如果用戶流量組成在模型訓練和預測期間發生顯著變化，則模型效能可能會降低。 例如，假設在模型訓練階段中，只有區段A中使用者的資料可供使用，但訓練的模型用於產生區段B中使用者的預測，則可能會影響模型效能。
* **選件效能在短時間內不會大幅變更** 因為此模型會每週更新，而效能的變更會隨著模型更新而傳達。 例如，一種產品以前很流行，但一份公開報告指出該產品有害於我們的健康，而且該產品很快就不受歡迎。 在此案例中，模型可以繼續預測此產品，直到模型隨使用者行為的變更而更新為止。

## 運作方式 {#how}

自動個人化會學習選件、使用者資訊和情境資訊之間的複雜功能互動，以向使用者建議個人化選件。 特徵是模型的輸入。

有3種功能：

| 功能類型 | 如何為模型新增功能 |
|--------------|----------------------------|
| 決策物件(placementID、activityID、decisionScopeID) | 傳送至AEP的決策管理意見反應事件的一部分 |
| 區段 | 建立「排名AI」模型時，可新增0-50個區段作為功能 |
| 內容資料 | 傳送至AEP的決策意見反應事件的一部分。 要添加到架構的可用上下文資料：商務詳細資訊，渠道詳細資訊，應用程式詳細資訊， Web詳細資訊，環境詳細資訊，設備詳細資訊， placeContext |

模型分為兩個階段：

* 在 **離線模型訓練** 階段，模型是通過學習和記憶歷史資料中的特徵交互來訓練的。
* 在 **線上推理** 階段中，候選選件會根據模型產生的即時分數來排名。 與傳統的協作篩選技術不同，自動個人化是一種基於深度學習的推薦方法，能夠包含和學習複雜和非線性的特徵交互模式。

以下是簡化的範例，以說明自動個人化背後的基本理念。 假設我們有一個資料集，可儲存使用者和選件之間的歷史互動，如圖1所示。 有：
* 兩個選件，offer_1和offer_2,
* 特徵1和特徵2
* 回應欄。

feature_1、feature_2和回應的值為0或1。 當查看圖1中的藍色框和橙色框時，我們可以發現，對於offer_1，當feature_1和feature_2具有相同值時，響應更可能為1；而對於offer_2，當feature_1為0且feature_2為1時，標籤更可能為1。 我們也可以看到在紅色方塊中，feature1為0且feature2為1且回應為0時，會提供offer1。 根據我們在橘色方塊中看到的模式，當feature_1為0且feature_2為1時，offer_2可能是更好的建議。

基本上，這是學習和記憶歷史特徵互動並運用這些互動來產生個人化預測的想法。

![](../assets/perso-ranking-schema.png)

## 冷啟動問題 {#cold-start}

當沒有足夠的資料可提供建議時，就會發生冷啟動問題。 針對自動個人化，有兩種冷啟動問題。

* **建立沒有歷史資料的新排名策略後**，選件會隨機提供一段時間以收集資料，而資料將用於訓練第一個模型。
* A **第一個模型發佈後**，則會將總流量的10%分配給隨機處理，而90%的流量將用於模型建議。 因此，如果將新選件新增至排名策略，這些選件會隨著10%的流量提供。 針對這些選件收集的資料會決定當模型持續更新時，在90%的流量中選取該選件的次數。

## 再培訓 {#re-training}

每週都會對模型進行重新訓練，以了解最新的功能互動，並減輕模型效能下降的影響。
