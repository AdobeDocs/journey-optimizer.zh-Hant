---
product: experience platform
solution: Experience Platform
title: 個人化最佳化模型
description: 進一步瞭解個人化最佳化模型
feature: Ranking Formulas
role: User
level: Intermediate
exl-id: c73b3092-e96d-4957-88e6-500e99542782
source-git-commit: f2174848c70610fc543ea9ddf766f0f7e579053a
workflow-type: tm+mt
source-wordcount: '781'
ht-degree: 1%

---

# 個人化最佳化模型 {#personalized-optimization-model}

## 概觀 {#overview}

自動個人化運用受監督的機器學習和深度學習中的先進技術，讓業務使用者（行銷人員）可定義業務目標，並利用其客戶資料來訓練業務導向的模型，以提供個人化優惠並最大化KPI。

## 主要模型假設和限制 {#key}

為了最大化使用自動個人化的優勢，請注意一些重要假設和限制。

* **優惠方案之間的差異已足夠，因此使用者所考慮的優惠方案間會有不同的偏好設定**. 如果優惠方案太相似，則產生的模型產生的影響會較小，因為回應似乎是隨機的。
例如，如果銀行有兩個信用卡優惠方案，唯一差異是顏色，那麼建議使用哪張卡可能無關緊要，但如果每張卡都有不同的詞語，這就能解釋為什麼某些客戶會選擇一張卡片，並提供足夠的優惠方案差異，以建立更有影響力的模型。
* **使用者流量構成穩定**. 如果使用者流量構成在模型訓練和預測期間發生大幅變更，模型效能可能會降低。 例如，假設在模型訓練階段，只有對象A中使用者的資料可用，但已訓練的模型用於產生對象B中使用者的預測，然後模型效能可能會受到影響。
* **優惠方案效能不會在短時間內大幅改變** 此模型每週更新時，效能變更會隨著模型更新而傳遞。 例如，某產品之前非常受歡迎，但公開報告指出該產品對我們的健康有害，因此該產品很快變得不受歡迎。 在此案例中，模型可以繼續預測此產品，直到模型更新為使用者行為的變化。

## 運作方式 {#how}

此模型會學習優惠方案、使用者資訊和情境資訊之間的複雜功能互動，以向一般使用者建議個人化優惠方案。 特徵是模型的輸入。

共有3種功能：

| 功能型別 | 如何為模型新增特徵 |
|--------------|----------------------------|
| 決策物件(placementID、activityID、decisionScopeID) | 傳送至AEP的決定管理意見體驗事件的一部分 |
| 對象 | 建立排名AI模型時，可新增0至50個受眾作為功能 |
| 內容資料 | 傳送至AEP的決策回饋體驗事件的一部分。 可新增至結構描述的可用內容資料：商務詳細資料、通道詳細資料、應用程式詳細資料、網頁詳細資料、環境詳細資料、裝置詳細資料、placeContext |

模型有兩個階段：

* 在 **離線模型訓練** 階段：藉由學習和記憶歷史資料中的特徵互動來訓練模型。
* 在 **線上推斷** 階段，系統會根據模型產生的即時分數來排名候選人優惠。 傳統合作篩選技術很難納入使用者和選件的功能，而自動個人化是一種深度學習型推薦方法，能夠包含和學習複雜和非線性功能的互動模式。

以下是說明自動個人化背後基本概念的簡化範例。 假設我們有一個資料集，儲存使用者和選件之間的歷史互動，如圖1所示。 有：
* 兩個選件，offer_1和offer_2，
* 兩個特徵，feature_1和feature_2，
* 回應欄。

feature_1、feature_2和回應的值是0或1。 檢視圖1中的藍色方塊和橙色方塊時，我們可以發現，對於offer_1，當feature_1和feature_2具有相同的值時，回應更有可能是1，而對於offer_2，當feature_1為0和feature_2為1時，標籤更有可能是1。 我們也可以看到在紅色方塊中，當feature_1為0且feature_2為1且回應為0時，會提供offer_1。 根據我們在橘色方塊中看到的模式，當feature_1為0且feature_2為1時，offer_2可能是更好的建議。

基本上，這是學習和記憶歷史功能互動，並套用這些互動以產生個人化預測的想法。

![](../assets/perso-ranking-schema.png)

## 冷啟動問題 {#cold-start}

當沒有足夠的資料可提出建議時，就會發生冷啟動問題。 對於自動個人化，有兩種冷啟動問題。

* **建立無歷史資料的新AI模型後**，選件將會隨機提供一段時間以收集資料，而資料將會用於訓練第一個模型。
* **第一個模型發行後**，總流量的10%將分配給隨機服務，而90%的流量將用於模型推薦。 因此，如果新優惠方案新增到AI模型，它們將會作為10%流量的一部分提供。 隨著模型持續更新，針對這些優惠方案收集的資料將決定從90%的流量中選取的次數。

## 重新訓練 {#re-training}

模型將接受重新培訓，以學習最新的功能互動，並每週緩解模型效能的下降。
